{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch\n",
    "\n",
    "![pytorch](img/pytorch.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.14071872, -1.73487554],\n",
       "       [-0.85170154,  0.98727216],\n",
       "       [ 0.16762812,  0.43609718],\n",
       "       [ 1.38676303, -0.46687341],\n",
       "       [-1.28889297,  0.57948545],\n",
       "       [ 1.16824409,  0.27015179],\n",
       "       [ 0.16671552, -0.80818652],\n",
       "       [ 0.29665347,  0.16198606],\n",
       "       [-1.35441872,  0.11755796],\n",
       "       [-0.4238943 , -0.29595254]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randn(10, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0807,  0.5361],\n",
       "        [-0.3592,  0.6331],\n",
       "        [-1.9988, -2.3001],\n",
       "        [-0.8135,  0.6358],\n",
       "        [ 0.4400,  0.7665],\n",
       "        [-0.5996,  1.7329],\n",
       "        [ 0.1236,  0.1532],\n",
       "        [ 0.5359, -3.0259],\n",
       "        [ 0.6837, -0.7039],\n",
       "        [-0.4395, -1.3465]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(10, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRecurrentNetwork(nn.Module):\n",
    "    def __init__(self, input_size, output_size, embedding_size=128, hidden_size=128):\n",
    "        super(SimpleRecurrentNetwork, self).__init__()\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "    \n",
    "        self.emb = nn.Embedding(input_size, embedding_size)\n",
    "        self.gru = nn.GRU(input_size=embedding_size, hidden_size=hidden_size, num_layers=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.emb(x)\n",
    "        _, x = self.gru(x)\n",
    "        x = self.relu(x.squeeze(0))\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleRecurrentNetwork(input_size=128, output_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleRecurrentNetwork(\n",
       "  (emb): Embedding(128, 128)\n",
       "  (gru): GRU(128, 128)\n",
       "  (relu): ReLU()\n",
       "  (linear): Linear(in_features=128, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example\n",
    "\n",
    "\n",
    "data: https://ml-challenge.mercadolibre.com/downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>label_quality</th>\n",
       "      <th>language</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Projeto Unidade Hidraulica 3000 Psi</td>\n",
       "      <td>reliable</td>\n",
       "      <td>portuguese</td>\n",
       "      <td>AIR_COMPRESSORS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Tapete Capacho 120x60 Churrasqueira + Frete Gr...</td>\n",
       "      <td>reliable</td>\n",
       "      <td>portuguese</td>\n",
       "      <td>CARPETS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Camiseta Raglan Crepúsculo Jealous Baby Look</td>\n",
       "      <td>reliable</td>\n",
       "      <td>portuguese</td>\n",
       "      <td>T_SHIRTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Unidade De Dvd Gravador Com Defeito Apenas Par...</td>\n",
       "      <td>reliable</td>\n",
       "      <td>portuguese</td>\n",
       "      <td>DVD_RECORDERS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Fan  Dell R320 / R420 0hr6c0 - 24h</td>\n",
       "      <td>reliable</td>\n",
       "      <td>portuguese</td>\n",
       "      <td>DESKTOP_COMPUTER_COOLERS_AND_FANS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title label_quality  \\\n",
       "0                Projeto Unidade Hidraulica 3000 Psi      reliable   \n",
       "1  Tapete Capacho 120x60 Churrasqueira + Frete Gr...      reliable   \n",
       "2       Camiseta Raglan Crepúsculo Jealous Baby Look      reliable   \n",
       "3  Unidade De Dvd Gravador Com Defeito Apenas Par...      reliable   \n",
       "4                 Fan  Dell R320 / R420 0hr6c0 - 24h      reliable   \n",
       "\n",
       "     language                           category  \n",
       "0  portuguese                    AIR_COMPRESSORS  \n",
       "1  portuguese                            CARPETS  \n",
       "2  portuguese                           T_SHIRTS  \n",
       "3  portuguese                      DVD_RECORDERS  \n",
       "4  portuguese  DESKTOP_COMPUTER_COOLERS_AND_FANS  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import data\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_x, field_y = data.Field(), data.LabelField()\n",
    "dataset = data.TabularDataset(path='data/train.csv', format='csv',\n",
    "                              fields=[('title', field_x), \n",
    "                                      ('label_quality', None),\n",
    "                                      ('language', None),\n",
    "                                      ('category', field_y)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid = dataset.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter, val_iter = data.BucketIterator.splits(\n",
    "    (train, valid), batch_sizes=(16, 16),\n",
    "    sort_key=lambda x: len(x.title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_x.build_vocab(dataset, min_freq=10)\n",
    "field_y.build_vocab(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model = SimpleRecurrentNetwork(input_size=len(field_x.vocab), output_size=len(field_y.vocab))\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1321, 878)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(field_x.vocab), len(field_y.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0/438, Train Loss: 6.7495\n",
      "Iteration: 10/438, Train Loss: 6.8218\n",
      "Iteration: 20/438, Train Loss: 6.7216\n",
      "Iteration: 30/438, Train Loss: 6.6746\n",
      "Iteration: 40/438, Train Loss: 6.6425\n",
      "Iteration: 50/438, Train Loss: 6.6148\n",
      "Iteration: 60/438, Train Loss: 6.5658\n",
      "Iteration: 70/438, Train Loss: 6.5481\n",
      "Iteration: 80/438, Train Loss: 6.5233\n",
      "Iteration: 90/438, Train Loss: 6.5044\n",
      "Iteration: 100/438, Train Loss: 6.4769\n",
      "Iteration: 110/438, Train Loss: 6.4428\n",
      "Iteration: 120/438, Train Loss: 6.4052\n",
      "Iteration: 130/438, Train Loss: 6.3756\n",
      "Iteration: 140/438, Train Loss: 6.3454\n",
      "Iteration: 150/438, Train Loss: 6.3252\n",
      "Iteration: 160/438, Train Loss: 6.2997\n",
      "Iteration: 170/438, Train Loss: 6.2633\n",
      "Iteration: 180/438, Train Loss: 6.2294\n",
      "Iteration: 190/438, Train Loss: 6.1931\n",
      "Iteration: 200/438, Train Loss: 6.1582\n",
      "Iteration: 210/438, Train Loss: 6.1286\n",
      "Iteration: 220/438, Train Loss: 6.1085\n",
      "Iteration: 230/438, Train Loss: 6.0684\n",
      "Iteration: 240/438, Train Loss: 6.0303\n",
      "Iteration: 250/438, Train Loss: 5.9894\n",
      "Iteration: 260/438, Train Loss: 5.9576\n",
      "Iteration: 270/438, Train Loss: 5.9350\n",
      "Iteration: 280/438, Train Loss: 5.8922\n",
      "Iteration: 290/438, Train Loss: 5.8560\n",
      "Iteration: 300/438, Train Loss: 5.8194\n",
      "Iteration: 310/438, Train Loss: 5.7917\n",
      "Iteration: 320/438, Train Loss: 5.7767\n",
      "Iteration: 330/438, Train Loss: 5.7377\n",
      "Iteration: 340/438, Train Loss: 5.7065\n",
      "Iteration: 350/438, Train Loss: 5.6887\n",
      "Iteration: 360/438, Train Loss: 5.6709\n",
      "Iteration: 370/438, Train Loss: 5.6394\n",
      "Iteration: 380/438, Train Loss: 5.6135\n",
      "Iteration: 390/438, Train Loss: 5.5938\n",
      "Iteration: 400/438, Train Loss: 5.5740\n",
      "Iteration: 410/438, Train Loss: 5.5487\n",
      "Iteration: 420/438, Train Loss: 5.5180\n",
      "Iteration: 430/438, Train Loss: 5.5014\n",
      "Epoch:   0, Evaluatio Loss: 867.4226\n"
     ]
    }
   ],
   "source": [
    "total_iters = len(train_iter)\n",
    "\n",
    "for e in range(1):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for i, batch in enumerate(train_iter):\n",
    "        optimizer.zero_grad()\n",
    "        x, y = batch.title, batch.category\n",
    "        output = model(x)\n",
    "        loss = criterion(output, y)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        if i % 10 == 0:\n",
    "            print(f'Iteration: {i}/{total_iters}, Train Loss: {train_loss / (i + 1):.4f}')\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        eval_loss = 0\n",
    "        for batch in val_iter:\n",
    "            x, y = batch.title, batch.category\n",
    "            output = model(x)\n",
    "            loss = criterion(output, y)\n",
    "            eval_loss += loss.item()\n",
    "        print(f'Epoch: {e:3}, Evaluatio Loss: {eval_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y.numpy(), torch.argmax(output, dim=1).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (drug-disc)",
   "language": "python",
   "name": "drug-disc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
